{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eec7af1-5b29-4a37-aec6-505866c32c9f",
   "metadata": {},
   "source": [
    "# SOTA-ish MNIST MLP\n",
    "Simple MLP architecture that achieves roughly SOTA performance (>98%) on MNIST dataset within **30** epochs (50 training epochs shown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c384dee8-b993-4d7c-8adb-7ea0978f8278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df91dcbe-b1e8-4598-a22f-fb58fb35f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "transforms = v2.Compose([\n",
    "    # v2.RandomResizedCrop(size=(28, 28), antialias=True),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomRotation(degrees=15),\n",
    "    # v2.ToDtype(torch.float32, scale=True),\n",
    "    # v2.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms,\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78d74a2c-7231-497f-9fa6-594c1b2cbc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dl = DataLoader(training_data, batch_size = BATCH_SIZE)\n",
    "test_dl = DataLoader(test_data, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a893a66-9f09-4f07-99fa-44c5332f2aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f8b057-af86-4a6c-a648-883959fc9e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_block = nn.Sequential(\n",
    "            nn.Linear(28*28, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 384),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm1d(192),\n",
    "            nn.Linear(384, 10),\n",
    "            # nn.Softmax(dim=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        probs = self.linear_block(x)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59ea0c3f-7227-4038-9f08-d800f887cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            # print(\"PREDICTION: \", pred)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15db69b6-22a9-45d7-b123-12679f52874e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.307436  [   64/60000]\n",
      "loss: 0.594470  [ 6464/60000]\n",
      "loss: 0.535015  [12864/60000]\n",
      "loss: 0.401990  [19264/60000]\n",
      "loss: 0.375865  [25664/60000]\n",
      "loss: 0.408990  [32064/60000]\n",
      "loss: 0.354631  [38464/60000]\n",
      "loss: 0.326443  [44864/60000]\n",
      "loss: 0.263131  [51264/60000]\n",
      "loss: 0.611126  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.243021 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.224656  [   64/60000]\n",
      "loss: 0.382130  [ 6464/60000]\n",
      "loss: 0.320709  [12864/60000]\n",
      "loss: 0.321481  [19264/60000]\n",
      "loss: 0.268204  [25664/60000]\n",
      "loss: 0.335202  [32064/60000]\n",
      "loss: 0.254348  [38464/60000]\n",
      "loss: 0.309981  [44864/60000]\n",
      "loss: 0.206965  [51264/60000]\n",
      "loss: 0.276780  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.1%, Avg loss: 0.158749 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.146737  [   64/60000]\n",
      "loss: 0.159576  [ 6464/60000]\n",
      "loss: 0.295618  [12864/60000]\n",
      "loss: 0.243006  [19264/60000]\n",
      "loss: 0.294980  [25664/60000]\n",
      "loss: 0.163240  [32064/60000]\n",
      "loss: 0.110110  [38464/60000]\n",
      "loss: 0.124165  [44864/60000]\n",
      "loss: 0.227393  [51264/60000]\n",
      "loss: 0.287246  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.139280 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.089928  [   64/60000]\n",
      "loss: 0.187764  [ 6464/60000]\n",
      "loss: 0.199289  [12864/60000]\n",
      "loss: 0.191931  [19264/60000]\n",
      "loss: 0.294050  [25664/60000]\n",
      "loss: 0.206418  [32064/60000]\n",
      "loss: 0.123578  [38464/60000]\n",
      "loss: 0.374266  [44864/60000]\n",
      "loss: 0.056601  [51264/60000]\n",
      "loss: 0.173045  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Avg loss: 0.107653 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.085626  [   64/60000]\n",
      "loss: 0.277689  [ 6464/60000]\n",
      "loss: 0.273710  [12864/60000]\n",
      "loss: 0.128690  [19264/60000]\n",
      "loss: 0.075084  [25664/60000]\n",
      "loss: 0.289580  [32064/60000]\n",
      "loss: 0.087260  [38464/60000]\n",
      "loss: 0.185126  [44864/60000]\n",
      "loss: 0.158800  [51264/60000]\n",
      "loss: 0.372752  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.111082 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.142989  [   64/60000]\n",
      "loss: 0.179525  [ 6464/60000]\n",
      "loss: 0.301908  [12864/60000]\n",
      "loss: 0.166275  [19264/60000]\n",
      "loss: 0.074643  [25664/60000]\n",
      "loss: 0.120445  [32064/60000]\n",
      "loss: 0.114440  [38464/60000]\n",
      "loss: 0.119468  [44864/60000]\n",
      "loss: 0.131808  [51264/60000]\n",
      "loss: 0.319159  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.098452 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.081601  [   64/60000]\n",
      "loss: 0.205867  [ 6464/60000]\n",
      "loss: 0.259369  [12864/60000]\n",
      "loss: 0.230760  [19264/60000]\n",
      "loss: 0.159810  [25664/60000]\n",
      "loss: 0.094701  [32064/60000]\n",
      "loss: 0.243396  [38464/60000]\n",
      "loss: 0.387466  [44864/60000]\n",
      "loss: 0.048257  [51264/60000]\n",
      "loss: 0.181384  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.086472 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.088509  [   64/60000]\n",
      "loss: 0.138641  [ 6464/60000]\n",
      "loss: 0.261676  [12864/60000]\n",
      "loss: 0.170848  [19264/60000]\n",
      "loss: 0.153997  [25664/60000]\n",
      "loss: 0.164235  [32064/60000]\n",
      "loss: 0.132942  [38464/60000]\n",
      "loss: 0.240871  [44864/60000]\n",
      "loss: 0.130112  [51264/60000]\n",
      "loss: 0.385108  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.085398 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.118092  [   64/60000]\n",
      "loss: 0.143861  [ 6464/60000]\n",
      "loss: 0.082297  [12864/60000]\n",
      "loss: 0.118358  [19264/60000]\n",
      "loss: 0.054107  [25664/60000]\n",
      "loss: 0.117412  [32064/60000]\n",
      "loss: 0.154755  [38464/60000]\n",
      "loss: 0.111470  [44864/60000]\n",
      "loss: 0.131440  [51264/60000]\n",
      "loss: 0.197025  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.080706 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.104496  [   64/60000]\n",
      "loss: 0.197388  [ 6464/60000]\n",
      "loss: 0.105052  [12864/60000]\n",
      "loss: 0.208042  [19264/60000]\n",
      "loss: 0.069773  [25664/60000]\n",
      "loss: 0.145086  [32064/60000]\n",
      "loss: 0.135886  [38464/60000]\n",
      "loss: 0.252004  [44864/60000]\n",
      "loss: 0.089411  [51264/60000]\n",
      "loss: 0.174929  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.082890 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.086020  [   64/60000]\n",
      "loss: 0.109000  [ 6464/60000]\n",
      "loss: 0.102335  [12864/60000]\n",
      "loss: 0.178632  [19264/60000]\n",
      "loss: 0.038440  [25664/60000]\n",
      "loss: 0.223229  [32064/60000]\n",
      "loss: 0.122931  [38464/60000]\n",
      "loss: 0.207803  [44864/60000]\n",
      "loss: 0.139942  [51264/60000]\n",
      "loss: 0.314381  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.085887 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.107384  [   64/60000]\n",
      "loss: 0.135426  [ 6464/60000]\n",
      "loss: 0.197059  [12864/60000]\n",
      "loss: 0.176028  [19264/60000]\n",
      "loss: 0.110798  [25664/60000]\n",
      "loss: 0.143804  [32064/60000]\n",
      "loss: 0.059405  [38464/60000]\n",
      "loss: 0.120401  [44864/60000]\n",
      "loss: 0.040773  [51264/60000]\n",
      "loss: 0.131390  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.073752 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.072962  [   64/60000]\n",
      "loss: 0.084416  [ 6464/60000]\n",
      "loss: 0.185354  [12864/60000]\n",
      "loss: 0.164392  [19264/60000]\n",
      "loss: 0.103363  [25664/60000]\n",
      "loss: 0.165812  [32064/60000]\n",
      "loss: 0.137005  [38464/60000]\n",
      "loss: 0.203024  [44864/60000]\n",
      "loss: 0.138039  [51264/60000]\n",
      "loss: 0.175163  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.071397 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.115148  [   64/60000]\n",
      "loss: 0.167725  [ 6464/60000]\n",
      "loss: 0.165052  [12864/60000]\n",
      "loss: 0.137899  [19264/60000]\n",
      "loss: 0.081026  [25664/60000]\n",
      "loss: 0.082153  [32064/60000]\n",
      "loss: 0.119040  [38464/60000]\n",
      "loss: 0.170523  [44864/60000]\n",
      "loss: 0.140987  [51264/60000]\n",
      "loss: 0.100779  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.072028 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.104423  [   64/60000]\n",
      "loss: 0.114381  [ 6464/60000]\n",
      "loss: 0.128024  [12864/60000]\n",
      "loss: 0.072183  [19264/60000]\n",
      "loss: 0.061999  [25664/60000]\n",
      "loss: 0.121437  [32064/60000]\n",
      "loss: 0.069481  [38464/60000]\n",
      "loss: 0.127629  [44864/60000]\n",
      "loss: 0.115656  [51264/60000]\n",
      "loss: 0.126677  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.064527 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.103188  [   64/60000]\n",
      "loss: 0.173326  [ 6464/60000]\n",
      "loss: 0.183378  [12864/60000]\n",
      "loss: 0.109681  [19264/60000]\n",
      "loss: 0.058425  [25664/60000]\n",
      "loss: 0.092691  [32064/60000]\n",
      "loss: 0.080507  [38464/60000]\n",
      "loss: 0.117842  [44864/60000]\n",
      "loss: 0.093467  [51264/60000]\n",
      "loss: 0.119610  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.071451 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.157528  [   64/60000]\n",
      "loss: 0.092696  [ 6464/60000]\n",
      "loss: 0.231414  [12864/60000]\n",
      "loss: 0.156173  [19264/60000]\n",
      "loss: 0.098149  [25664/60000]\n",
      "loss: 0.123327  [32064/60000]\n",
      "loss: 0.053580  [38464/60000]\n",
      "loss: 0.107977  [44864/60000]\n",
      "loss: 0.077293  [51264/60000]\n",
      "loss: 0.210045  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.064974 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.078308  [   64/60000]\n",
      "loss: 0.148931  [ 6464/60000]\n",
      "loss: 0.073269  [12864/60000]\n",
      "loss: 0.133465  [19264/60000]\n",
      "loss: 0.135211  [25664/60000]\n",
      "loss: 0.104913  [32064/60000]\n",
      "loss: 0.156675  [38464/60000]\n",
      "loss: 0.128475  [44864/60000]\n",
      "loss: 0.089311  [51264/60000]\n",
      "loss: 0.180081  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.068640 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.033066  [   64/60000]\n",
      "loss: 0.175792  [ 6464/60000]\n",
      "loss: 0.123061  [12864/60000]\n",
      "loss: 0.094367  [19264/60000]\n",
      "loss: 0.058525  [25664/60000]\n",
      "loss: 0.055874  [32064/60000]\n",
      "loss: 0.064392  [38464/60000]\n",
      "loss: 0.144021  [44864/60000]\n",
      "loss: 0.095725  [51264/60000]\n",
      "loss: 0.212674  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.067701 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.028885  [   64/60000]\n",
      "loss: 0.095980  [ 6464/60000]\n",
      "loss: 0.099951  [12864/60000]\n",
      "loss: 0.045729  [19264/60000]\n",
      "loss: 0.090359  [25664/60000]\n",
      "loss: 0.062847  [32064/60000]\n",
      "loss: 0.065584  [38464/60000]\n",
      "loss: 0.052631  [44864/60000]\n",
      "loss: 0.132918  [51264/60000]\n",
      "loss: 0.123416  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.064068 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.086548  [   64/60000]\n",
      "loss: 0.115741  [ 6464/60000]\n",
      "loss: 0.098619  [12864/60000]\n",
      "loss: 0.073629  [19264/60000]\n",
      "loss: 0.084719  [25664/60000]\n",
      "loss: 0.088799  [32064/60000]\n",
      "loss: 0.122378  [38464/60000]\n",
      "loss: 0.077674  [44864/60000]\n",
      "loss: 0.127534  [51264/60000]\n",
      "loss: 0.091632  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.067184 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.096650  [   64/60000]\n",
      "loss: 0.120453  [ 6464/60000]\n",
      "loss: 0.095168  [12864/60000]\n",
      "loss: 0.127047  [19264/60000]\n",
      "loss: 0.122136  [25664/60000]\n",
      "loss: 0.034413  [32064/60000]\n",
      "loss: 0.061504  [38464/60000]\n",
      "loss: 0.205928  [44864/60000]\n",
      "loss: 0.126476  [51264/60000]\n",
      "loss: 0.284827  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.061446 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.031294  [   64/60000]\n",
      "loss: 0.151727  [ 6464/60000]\n",
      "loss: 0.155045  [12864/60000]\n",
      "loss: 0.043999  [19264/60000]\n",
      "loss: 0.202594  [25664/60000]\n",
      "loss: 0.034673  [32064/60000]\n",
      "loss: 0.052296  [38464/60000]\n",
      "loss: 0.160356  [44864/60000]\n",
      "loss: 0.100613  [51264/60000]\n",
      "loss: 0.006549  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.067407 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.055675  [   64/60000]\n",
      "loss: 0.083131  [ 6464/60000]\n",
      "loss: 0.114346  [12864/60000]\n",
      "loss: 0.105330  [19264/60000]\n",
      "loss: 0.007456  [25664/60000]\n",
      "loss: 0.044465  [32064/60000]\n",
      "loss: 0.118078  [38464/60000]\n",
      "loss: 0.141945  [44864/60000]\n",
      "loss: 0.248183  [51264/60000]\n",
      "loss: 0.059271  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.066988 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.060384  [   64/60000]\n",
      "loss: 0.133400  [ 6464/60000]\n",
      "loss: 0.030818  [12864/60000]\n",
      "loss: 0.293653  [19264/60000]\n",
      "loss: 0.055610  [25664/60000]\n",
      "loss: 0.062825  [32064/60000]\n",
      "loss: 0.095984  [38464/60000]\n",
      "loss: 0.124447  [44864/60000]\n",
      "loss: 0.129166  [51264/60000]\n",
      "loss: 0.152659  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.063945 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.016855  [   64/60000]\n",
      "loss: 0.041415  [ 6464/60000]\n",
      "loss: 0.231186  [12864/60000]\n",
      "loss: 0.247591  [19264/60000]\n",
      "loss: 0.027510  [25664/60000]\n",
      "loss: 0.037566  [32064/60000]\n",
      "loss: 0.088353  [38464/60000]\n",
      "loss: 0.125281  [44864/60000]\n",
      "loss: 0.060661  [51264/60000]\n",
      "loss: 0.019904  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.058870 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.149096  [   64/60000]\n",
      "loss: 0.086997  [ 6464/60000]\n",
      "loss: 0.066246  [12864/60000]\n",
      "loss: 0.094467  [19264/60000]\n",
      "loss: 0.059913  [25664/60000]\n",
      "loss: 0.084368  [32064/60000]\n",
      "loss: 0.052184  [38464/60000]\n",
      "loss: 0.107022  [44864/60000]\n",
      "loss: 0.062250  [51264/60000]\n",
      "loss: 0.071916  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.055254 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.046761  [   64/60000]\n",
      "loss: 0.038893  [ 6464/60000]\n",
      "loss: 0.115707  [12864/60000]\n",
      "loss: 0.114321  [19264/60000]\n",
      "loss: 0.019080  [25664/60000]\n",
      "loss: 0.151716  [32064/60000]\n",
      "loss: 0.064772  [38464/60000]\n",
      "loss: 0.162424  [44864/60000]\n",
      "loss: 0.044255  [51264/60000]\n",
      "loss: 0.179201  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.053998 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.056801  [   64/60000]\n",
      "loss: 0.153186  [ 6464/60000]\n",
      "loss: 0.120146  [12864/60000]\n",
      "loss: 0.183309  [19264/60000]\n",
      "loss: 0.011222  [25664/60000]\n",
      "loss: 0.059179  [32064/60000]\n",
      "loss: 0.075367  [38464/60000]\n",
      "loss: 0.036945  [44864/60000]\n",
      "loss: 0.127708  [51264/60000]\n",
      "loss: 0.078449  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.057559 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.097933  [   64/60000]\n",
      "loss: 0.016638  [ 6464/60000]\n",
      "loss: 0.134480  [12864/60000]\n",
      "loss: 0.073632  [19264/60000]\n",
      "loss: 0.097385  [25664/60000]\n",
      "loss: 0.068563  [32064/60000]\n",
      "loss: 0.023158  [38464/60000]\n",
      "loss: 0.148005  [44864/60000]\n",
      "loss: 0.101009  [51264/60000]\n",
      "loss: 0.066572  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.054176 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.052694  [   64/60000]\n",
      "loss: 0.037910  [ 6464/60000]\n",
      "loss: 0.050983  [12864/60000]\n",
      "loss: 0.086956  [19264/60000]\n",
      "loss: 0.014478  [25664/60000]\n",
      "loss: 0.013990  [32064/60000]\n",
      "loss: 0.052205  [38464/60000]\n",
      "loss: 0.081427  [44864/60000]\n",
      "loss: 0.073026  [51264/60000]\n",
      "loss: 0.061805  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.054293 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.039540  [   64/60000]\n",
      "loss: 0.172973  [ 6464/60000]\n",
      "loss: 0.108308  [12864/60000]\n",
      "loss: 0.026546  [19264/60000]\n",
      "loss: 0.117261  [25664/60000]\n",
      "loss: 0.049795  [32064/60000]\n",
      "loss: 0.166449  [38464/60000]\n",
      "loss: 0.067389  [44864/60000]\n",
      "loss: 0.168856  [51264/60000]\n",
      "loss: 0.071113  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.055989 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.019573  [   64/60000]\n",
      "loss: 0.068875  [ 6464/60000]\n",
      "loss: 0.053316  [12864/60000]\n",
      "loss: 0.127165  [19264/60000]\n",
      "loss: 0.017174  [25664/60000]\n",
      "loss: 0.019809  [32064/60000]\n",
      "loss: 0.062040  [38464/60000]\n",
      "loss: 0.072644  [44864/60000]\n",
      "loss: 0.160198  [51264/60000]\n",
      "loss: 0.009035  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.056198 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.066787  [   64/60000]\n",
      "loss: 0.128367  [ 6464/60000]\n",
      "loss: 0.083841  [12864/60000]\n",
      "loss: 0.044962  [19264/60000]\n",
      "loss: 0.030872  [25664/60000]\n",
      "loss: 0.051098  [32064/60000]\n",
      "loss: 0.061176  [38464/60000]\n",
      "loss: 0.052835  [44864/60000]\n",
      "loss: 0.094073  [51264/60000]\n",
      "loss: 0.039559  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.054960 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.016032  [   64/60000]\n",
      "loss: 0.046087  [ 6464/60000]\n",
      "loss: 0.020889  [12864/60000]\n",
      "loss: 0.050790  [19264/60000]\n",
      "loss: 0.035303  [25664/60000]\n",
      "loss: 0.147045  [32064/60000]\n",
      "loss: 0.109842  [38464/60000]\n",
      "loss: 0.133688  [44864/60000]\n",
      "loss: 0.097639  [51264/60000]\n",
      "loss: 0.023459  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.059877 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.092738  [   64/60000]\n",
      "loss: 0.094750  [ 6464/60000]\n",
      "loss: 0.131207  [12864/60000]\n",
      "loss: 0.068630  [19264/60000]\n",
      "loss: 0.010997  [25664/60000]\n",
      "loss: 0.013506  [32064/60000]\n",
      "loss: 0.022926  [38464/60000]\n",
      "loss: 0.054553  [44864/60000]\n",
      "loss: 0.060297  [51264/60000]\n",
      "loss: 0.029207  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.054658 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.108061  [   64/60000]\n",
      "loss: 0.052252  [ 6464/60000]\n",
      "loss: 0.083389  [12864/60000]\n",
      "loss: 0.020459  [19264/60000]\n",
      "loss: 0.068183  [25664/60000]\n",
      "loss: 0.078605  [32064/60000]\n",
      "loss: 0.100308  [38464/60000]\n",
      "loss: 0.040280  [44864/60000]\n",
      "loss: 0.099151  [51264/60000]\n",
      "loss: 0.020430  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.055387 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.031904  [   64/60000]\n",
      "loss: 0.134276  [ 6464/60000]\n",
      "loss: 0.073280  [12864/60000]\n",
      "loss: 0.066878  [19264/60000]\n",
      "loss: 0.072784  [25664/60000]\n",
      "loss: 0.061950  [32064/60000]\n",
      "loss: 0.058477  [38464/60000]\n",
      "loss: 0.078944  [44864/60000]\n",
      "loss: 0.059193  [51264/60000]\n",
      "loss: 0.098037  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.052892 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.051213  [   64/60000]\n",
      "loss: 0.115412  [ 6464/60000]\n",
      "loss: 0.079689  [12864/60000]\n",
      "loss: 0.043996  [19264/60000]\n",
      "loss: 0.019572  [25664/60000]\n",
      "loss: 0.090362  [32064/60000]\n",
      "loss: 0.009448  [38464/60000]\n",
      "loss: 0.197158  [44864/60000]\n",
      "loss: 0.053172  [51264/60000]\n",
      "loss: 0.018434  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.051739 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.053232  [   64/60000]\n",
      "loss: 0.063113  [ 6464/60000]\n",
      "loss: 0.109830  [12864/60000]\n",
      "loss: 0.076228  [19264/60000]\n",
      "loss: 0.008607  [25664/60000]\n",
      "loss: 0.023751  [32064/60000]\n",
      "loss: 0.036384  [38464/60000]\n",
      "loss: 0.061213  [44864/60000]\n",
      "loss: 0.134644  [51264/60000]\n",
      "loss: 0.020424  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.049339 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.028994  [   64/60000]\n",
      "loss: 0.044654  [ 6464/60000]\n",
      "loss: 0.015916  [12864/60000]\n",
      "loss: 0.066253  [19264/60000]\n",
      "loss: 0.018773  [25664/60000]\n",
      "loss: 0.031508  [32064/60000]\n",
      "loss: 0.015387  [38464/60000]\n",
      "loss: 0.076042  [44864/60000]\n",
      "loss: 0.161369  [51264/60000]\n",
      "loss: 0.207664  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.052480 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.030930  [   64/60000]\n",
      "loss: 0.122555  [ 6464/60000]\n",
      "loss: 0.045957  [12864/60000]\n",
      "loss: 0.184931  [19264/60000]\n",
      "loss: 0.045021  [25664/60000]\n",
      "loss: 0.050362  [32064/60000]\n",
      "loss: 0.017399  [38464/60000]\n",
      "loss: 0.058465  [44864/60000]\n",
      "loss: 0.219872  [51264/60000]\n",
      "loss: 0.027765  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.048737 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.009197  [   64/60000]\n",
      "loss: 0.101289  [ 6464/60000]\n",
      "loss: 0.054641  [12864/60000]\n",
      "loss: 0.220947  [19264/60000]\n",
      "loss: 0.015207  [25664/60000]\n",
      "loss: 0.014619  [32064/60000]\n",
      "loss: 0.008134  [38464/60000]\n",
      "loss: 0.215057  [44864/60000]\n",
      "loss: 0.087923  [51264/60000]\n",
      "loss: 0.065237  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.054977 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.069453  [   64/60000]\n",
      "loss: 0.068573  [ 6464/60000]\n",
      "loss: 0.034375  [12864/60000]\n",
      "loss: 0.053966  [19264/60000]\n",
      "loss: 0.033434  [25664/60000]\n",
      "loss: 0.096801  [32064/60000]\n",
      "loss: 0.018838  [38464/60000]\n",
      "loss: 0.061228  [44864/60000]\n",
      "loss: 0.117131  [51264/60000]\n",
      "loss: 0.223013  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.049491 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.003892  [   64/60000]\n",
      "loss: 0.046878  [ 6464/60000]\n",
      "loss: 0.039089  [12864/60000]\n",
      "loss: 0.110090  [19264/60000]\n",
      "loss: 0.143090  [25664/60000]\n",
      "loss: 0.008752  [32064/60000]\n",
      "loss: 0.018035  [38464/60000]\n",
      "loss: 0.119783  [44864/60000]\n",
      "loss: 0.165422  [51264/60000]\n",
      "loss: 0.019322  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.049911 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.013493  [   64/60000]\n",
      "loss: 0.020353  [ 6464/60000]\n",
      "loss: 0.092493  [12864/60000]\n",
      "loss: 0.078041  [19264/60000]\n",
      "loss: 0.083450  [25664/60000]\n",
      "loss: 0.084123  [32064/60000]\n",
      "loss: 0.036829  [38464/60000]\n",
      "loss: 0.011875  [44864/60000]\n",
      "loss: 0.168300  [51264/60000]\n",
      "loss: 0.112536  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.050828 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.043257  [   64/60000]\n",
      "loss: 0.005133  [ 6464/60000]\n",
      "loss: 0.061820  [12864/60000]\n",
      "loss: 0.041796  [19264/60000]\n",
      "loss: 0.031916  [25664/60000]\n",
      "loss: 0.040414  [32064/60000]\n",
      "loss: 0.038625  [38464/60000]\n",
      "loss: 0.087718  [44864/60000]\n",
      "loss: 0.100004  [51264/60000]\n",
      "loss: 0.073197  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.045965 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.061068  [   64/60000]\n",
      "loss: 0.024884  [ 6464/60000]\n",
      "loss: 0.020982  [12864/60000]\n",
      "loss: 0.045767  [19264/60000]\n",
      "loss: 0.053968  [25664/60000]\n",
      "loss: 0.054103  [32064/60000]\n",
      "loss: 0.060469  [38464/60000]\n",
      "loss: 0.047991  [44864/60000]\n",
      "loss: 0.064896  [51264/60000]\n",
      "loss: 0.065442  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.051200 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.014372  [   64/60000]\n",
      "loss: 0.008661  [ 6464/60000]\n",
      "loss: 0.045063  [12864/60000]\n",
      "loss: 0.064132  [19264/60000]\n",
      "loss: 0.010480  [25664/60000]\n",
      "loss: 0.031223  [32064/60000]\n",
      "loss: 0.011292  [38464/60000]\n",
      "loss: 0.118319  [44864/60000]\n",
      "loss: 0.084835  [51264/60000]\n",
      "loss: 0.034197  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.049444 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.041997  [   64/60000]\n",
      "loss: 0.045280  [ 6464/60000]\n",
      "loss: 0.299470  [12864/60000]\n",
      "loss: 0.048518  [19264/60000]\n",
      "loss: 0.002322  [25664/60000]\n",
      "loss: 0.072718  [32064/60000]\n",
      "loss: 0.054333  [38464/60000]\n",
      "loss: 0.014471  [44864/60000]\n",
      "loss: 0.090285  [51264/60000]\n",
      "loss: 0.081639  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.050615 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NN().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=1e-3,\n",
    ")\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dl, model, loss_fn, optimizer)\n",
    "    test(test_dl, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93ac615-8eef-4fe8-97e6-e10a45860625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-jupyter]",
   "language": "python",
   "name": "conda-env-.conda-jupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
